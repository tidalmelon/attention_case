{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9842226a-3ba5-4ad1-ac1f-1d1f90ed9db1",
   "metadata": {},
   "source": [
    "[machine translation corpus](https://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547b052d-ed8e-41bc-8bad-47ce415f0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-04 18:40:22--  https://www.manythings.org/anki/cmn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1270861 (1.2M) [application/zip]\n",
      "Saving to: ‘./data/cmn-eng.zip’\n",
      "\n",
      "100%[======================================>] 1,270,861    370KB/s   in 3.4s   \n",
      "\n",
      "2023-02-04 18:40:27 (370 KB/s) - ‘./data/cmn-eng.zip’ saved [1270861/1270861]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/cmn-eng.zip -P ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ded6150-4ff8-4c49-9148-237bdbbf1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./data/cmn-eng.zip\n",
      "  inflating: ./data/cmn.txt          \n",
      "  inflating: ./data/_about.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip ./data/cmn-eng.zip -d ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbb38de-f4cd-4b84-91ed-9912a904542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import zhconv\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770662b6-bb78-470d-8d10-4b4c6abe8fa3",
   "metadata": {},
   "source": [
    "## load corpus\n",
    "\n",
    "load sentences pair in chinese and english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7497ff0a-b501-4b44-ba95-013b0b87e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    chi_list = []\n",
    "    eng_list = []\n",
    "    with open('./data/cmn.txt') as f:\n",
    "        for line in f:\n",
    "            eng_sent, chi_sent, _ = line.split('\\t')\n",
    "            \n",
    "            # traditional to simplified\n",
    "            # zhconv.convert('走開！', 'zh-cn')\n",
    "            chi_sent = zhconv.convert(chi_sent, 'zh-cn')\n",
    "            \n",
    "            chi_list.append(chi_sent)\n",
    "            eng_list.append(eng_sent)\n",
    "    return chi_list, eng_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7824679-dab3-4e28-a3ce-54fb294f53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_list, eng_list = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa14d69-65cd-4c6f-b1b0-e31fc503ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('嗨。', 'Hi.'), ('你好。', 'Hi.'), ('你用跑的。', 'Run.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chi_list[:3], eng_list[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41435a34-f49c-4fe0-826d-7146916d2ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。',\n",
       "  \"It's very easy to sound natural in your own native language, and very easy to sound unnatural in your non-native language.\"),\n",
       " ('虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。',\n",
       "  \"I got fired from the company, but since I have a little money saved up, for the time being, I won't have trouble with living expenses.\"),\n",
       " ('如果一个人在成人前没有机会习得目标语言，他对该语言的认识达到母语者程度的机会是相当小的。',\n",
       "  \"If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chi_list[-3:], eng_list[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a166472-e708-42f5-aeba-f536bd8b436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26a797-874f-4f22-a8f4-48d4e7cfd8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5ad6f-e3d7-468d-ace6-2dddffedf2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "330ac668-9e45-44d5-9e76-3f875583b513",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d815a95-608f-40de-882a-ab108ffa3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_space(word):\n",
    "    if not word:\n",
    "        # None ''\n",
    "        return True\n",
    "    if word.isspace():\n",
    "        #\\t \\n \\r \\u202f \\xa0\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a34d7f-f0cd-40bd-88e4-ec1ec2b6e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'recommend', 'item']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['', ' ', 'i' , 'recommend', 'item']\n",
    "[w for w in words if not is_space(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2e0128-da1d-4fce-b4f3-895263fb3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_space(text):\n",
    "    # for english only\n",
    "    # fill space before ,.!? which is convenient to tokenize\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "    \n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9da2b81-3a20-467b-b338-ed6afac5e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's very easy to sound natural in your own native language , and very easy to sound unnatural in your non-native language .\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_space(\"It's very easy to sound natural in your own native language, and very easy to sound unnatural in your non-native language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef7edb1-1472-42f2-a316-f41586273227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(chi_list, eng_list):\n",
    "    \n",
    "    source = []\n",
    "    for sent in chi_list:\n",
    "        words = jieba.cut(sent)\n",
    "        words = [w for w in words if not is_space(w)]\n",
    "        source.append(words)\n",
    "        \n",
    "    target = []\n",
    "    for sent in eng_list:\n",
    "        sent = sent.lower()\n",
    "        sent = fill_space(sent)\n",
    "        words = sent.split(' ')\n",
    "        words = [w for w in words if not is_space(w)]\n",
    "        target.append(words)\n",
    "        \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16f665-6ebd-4a77-9e0d-c158d914e088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a208996-08cd-40c9-b595-f28d6e862e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.410 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "source, target = tokenize(chi_list, eng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc62f12-8759-4dbd-ab1a-09582efa2c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['嗨', '。'], ['你好', '。'], ['你', '用', '跑', '的', '。'], ['住手', '！'], ['等等', '！']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c83258e-851c-4414-b770-28bc90ba45b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi', '.'], ['hi', '.'], ['run', '.'], ['stop', '!'], ['wait', '!']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824053e-2c46-4f44-97a6-5afd13130a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "757d22e3-c462-4477-b281-6075826b793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for sent_cn, sent_eng in zip(source, target):\n",
    "    arr.append([len(sent_cn), len(sent_eng)])\n",
    "arr = torch.tensor(arr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce2e8c39-d8f5-4376-b6cf-3f66eeb94aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([30., 34.]),\n",
       "indices=tensor([29362, 29370]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8270e1bf-49cb-43c6-97c6-4c6e2b5c6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6265, 7.2073])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4667d443-2d4b-4a35-a994-f72c384daa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_steps = 10, is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e81de-abcf-496f-93a8-4b2793ef892e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2cda031-f9be-4cff-baf9-023fdfb53882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    \"\"\"vocabulary\"\"\"\n",
    "    \n",
    "    def __init__(self, tokens, min_freq=0, reserved_tokens=['<pad>', '<bos>', '<eos>']):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        self._token_freqs = sorted(Counter(tokens).items(), key=lambda x: x[1], reverse=True)\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "        \n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) -1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token(indices)\n",
    "        return [self.idx_to_token[indice] for indice in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        # index for the unknown token\n",
    "        return 0\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8e1c9-1127-47a6-9d78-018d54aa7ec4",
   "metadata": {},
   "source": [
    "### vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b02c83d-40dd-41b7-a73e-51a30034e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d28d7a13-3046-46d9-aedd-b31cb703cd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['<pad>'], src_vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f80c0a70-4f49-4aad-b6da-0b039748d19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab[['<unk>', '<pad>', '<bos>', '<eos>', '。']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fabd49-a2ad-40f4-8877-ca3482497e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4feda06-9719-4549-9cb5-e672b474ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"truncate or pad sequence\"\"\"\n",
    "    if len(line) > num_steps: \n",
    "        # trancate\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token] * (num_steps - len(line)) # pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d532bd26-d5b1-4ffe-a6bb-899e1c6bde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(lines, vocab, num_steps):\n",
    "    \"\"\"transfrom text sequence of machine traslation into minibatches.\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    arr = [ truncate_pad(l, num_steps, vocab['<pad>'])  for l in lines]\n",
    "    arr = torch.tensor(arr)\n",
    "    \n",
    "    valid_len = (arr != vocab['<pad>']).type(torch.int32).sum(dim=1)\n",
    "    \n",
    "    return arr, valid_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa965b-7acc-428d-a3e1-aad7455f0e7d",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28d543ff-8c93-4b55-9f07-a1de1afb8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 128, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0aa0af1-7303-4493-bec2-3067dc5da8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_arr, src_valid_len = to_tensor(source, src_vocab, num_steps=num_steps)\n",
    "tgt_arr, tgt_valid_len = to_tensor(target, tgt_vocab, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44aa2e84-ed15-4219-9e7b-40d7aea7a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2500,    4,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1210,    4,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [   8,  112,  324,    6,    4,    3,    1,    1,    1,    1],\n",
       "         [4522,   72,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [2501,   72,    3,    1,    1,    1,    1,    1,    1,    1]]),\n",
       " tensor([3, 3, 6, 3, 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_arr[:5], src_valid_len[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a33b7002-3f5c-4f23-b6c2-e02f7650dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataloader(arr_list, batch_size, is_train=True):\n",
    "    dataset = TensorDataset(*arr_list)\n",
    "    return DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9159b013-ddf8-4671-ac1d-46249be26145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 3, 6, 3, 3]), tensor([10, 10, 10, 10, 10]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_valid_len[:5], src_valid_len[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12444e67-2571-49fe-a461-466038cb7604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a55f91a-4214-4228-b65e-06691ae1a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = to_dataloader((src_arr, src_valid_len, tgt_arr, tgt_valid_len), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "489252a7-c6a8-4264-a9af-d85de0510f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10]) torch.Size([128]) torch.Size([128, 10]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for e in iter(dataloader):\n",
    "    print(e[0].shape, e[1].shape, e[2].shape, e[3].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb50a0-1fd6-4dbb-874f-5813e612fda1",
   "metadata": {},
   "source": [
    "## seq2seq with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b31fe-2f31-4561-a67a-dc44c98f66ad",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae47863f-e9d3-4fa3-92e8-5fed78a01888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1aca821-ef1d-43a8-9292-d64a0b7d89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"Perform softmax operation by masking elements on the last axis.\"\"\"\n",
    "\n",
    "    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # On the last axis, replace masked elements with a very large negative\n",
    "        # value, whose exponentiation outputs 0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401cec2-0abe-4ceb-91db-081711f37dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dde83267-6d89-4b0d-9d34-b86177639448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The base decoder interface for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"The base class for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)\n",
    "        \n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "        \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "326455b5-739e-4580-824b-71644e554141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"Additive attention.\n",
    "\n",
    "    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # After dimension expansion, shape of `queries`: (`batch_size`, no. of\n",
    "        # queries, 1, `num_hiddens`) and shape of `keys`: (`batch_size`, 1,\n",
    "        # no. of key-value pairs, `num_hiddens`). Sum them up with\n",
    "        # broadcasting\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # There is only one output of `self.w_v`, so we remove the last\n",
    "        # one-dimensional entry from the shape. Shape of `scores`:\n",
    "        # (`batch_size`, no. of queries, no. of key-value pairs)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "        # dimension)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f6cac17-9c8d-4d29-9185-38e37d3e86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(Encoder):\n",
    "    \"\"\"The RNN encoder for sequence to sequence learning.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq`\"\"\"\n",
    "    # encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
    "        X = self.embedding(X)\n",
    "        # In RNN models, the first axis corresponds to time steps\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # When state is not mentioned, it defaults to zeros\n",
    "        output, state = self.rnn(X)\n",
    "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86475504-f3cf-4f5f-a5e4-55380ea5eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.attention = AdditiveAttention(num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size+num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "        \n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # encodet output:\n",
    "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        \n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "    \n",
    "        # return:\n",
    "        # outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "        # hidden_state.shape = [num_layers，batch_size，num_hiddens]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        # X.shape = [batch_size, num_steps]\n",
    "        \n",
    "        # return:\n",
    "        # enc_outputs = outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "        # hidden_state.shape = [num_layers，batch_size，num_hiddens]\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        \n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        # X.embedding.shape = [batch_size, num_steps, embed_size]\n",
    "        # X.shape = [num_steps, batch_size, embed_size]\n",
    "        \n",
    "        outputs, self._attention_weights = [], []\n",
    "        \n",
    "        # iterate num_steps or words:\n",
    "        for x in X:\n",
    "            # x.shape = [batch_size, embed_size]\n",
    "            \n",
    "            # hidden_state[-1].shape = [batch_size, num_hiddens] , alwasys only use the finnal layrers hidden_state\n",
    "            # unsqueeze.shape = [batch_size, 1, num_hiddens]\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # query.shape = [batch_size, 1, num_hiddens]\n",
    "            \n",
    "            # additive attention API:\n",
    "            # forward(self, queries, keys, values, valid_lens):\n",
    "            # queries = [batch_size, 查询的个数, 查询的维度] = [batch_size, num_queries, q]\n",
    "            # keys = [batch_size, “键－值”对的个数, 键的维度] = [batch_size, num_keys, k]\n",
    "            # values = [batch_size, “键－值”对的个数, 值得维度]\n",
    "            \n",
    "            # query.shape = [batch_size, num_steps(num_words), num_hiddens]\n",
    "            # query.shape = [batch_size, 1, num_hiddens]\n",
    "            # enc_outputs = keys = outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "            # enc_outputs =values = outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # context.shape = : 加权平均weight_mean = [batch_size, 查询的个数, 值的维度)\n",
    "            # context.shape = : 加权平均weight_mean = [batch_size, 1, num_hiddens)\n",
    "            \n",
    "            # x.unsqueeze.shape = [batch_size, 1, embed_size]\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1) # cat on the last dim\n",
    "            # x.shape = [batch_size, 1, embed_size+num_hiddens]\n",
    "            \n",
    "            # x.permute.shape = [1, batch_size, embed_size+num_hiddens]\n",
    "            # GRU.input.shape = [seq_len(num_steps, word_len), batch_size, num_hiddens=embed_size+num_hiddens] 符合预期\n",
    "            \n",
    "            # hidden_state.shape = [num_layers，batch_size，num_hiddens]\n",
    "            # GRU.h_0.shape = [number_layers, batch_size, num_hiddens]  符合预期，这个不需要cat拼接\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            # out.shape = [num_steps, batch_size, num_hiddens]  见下图， rnn 将x_t(embed_size+num_hiddens) 与 h_t-1 合并为 num_hiddens\n",
    "            # 注意哦，RNN的输入包含了Linear的in_features, 也包含Linear.out_features也是Linear的输入\n",
    "            # hidden_state = [num_layers, batch_size, num_hiddens=hidden_size]\n",
    "           \n",
    "            outputs.append(out)\n",
    "            # [ inner.shape = num_steps, batch_size, num_hiddens ] 经RNN合并后的num_hiddens\n",
    "            \n",
    "            \n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "            \n",
    "        # definition: dense = nn.Linear(num_hiddens, vocab_size)\n",
    "        # outpus.cat.shape = out.shape = [num_steps, batch_size, num_hiddens] 经RNN合并后的num_hiddens, 符合预期\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0)) # dim=0, 列叠加\n",
    "        # outputs.shape = [num_steps,batch_size,vocab_size], 符合预期 \n",
    "        \n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state, enc_valid_lens]\n",
    "        # outputs.shape = [batch_size, num_steps, vocab_size]\n",
    "        # enc_outputs = encoder_outputs keep it's value from encoder layer\n",
    "        # hidden_state.shape = [num_layers，batch_size，num_hiddens],   hidden_state keep it's shape, and it's values are updated\n",
    "    \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "067bfb10-fa07-42af-b3ff-e7e8a0e5b8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4581"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26efac52-def5-4233-b296-f2e8b88e6177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6537"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453dd19-581a-46c8-93ee-ef7950420fb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e54959fd-a59a-4ddb-815f-30b622eff0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3509212e-2944-43d8-a188-344fcddd64d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
    "\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f9a228-3f88-42f9-8730-3fc181f9eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator(object):\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95fa904a-c754-4f84-99e4-97c7345e1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6ed19d4-db9b-4814-99ce-0c19ac7cc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    \n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe691f-09b2-4c1f-9053-39e3f6efc79f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83a0f8d5-ad7e-47e5-91d0-6a3550c99c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 100, 128, 2, 0.1\n",
    "batch_size, num_steps = 128, 10\n",
    "lr = 0.005\n",
    "num_epochs = 100\n",
    "device = try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "491b8617-1f3f-4e18-a177-9ca1c42d5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0d399161-9b40-4177-a60a-78b19049a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "637d1e6e-70a8-4987-80e0-960fe3bc2b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Seq2SeqEncoder(\n",
       "    (embedding): Embedding(6537, 100)\n",
       "    (rnn): GRU(100, 128, num_layers=2, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Seq2SeqAttentionDecoder(\n",
       "    (attention): AdditiveAttention(\n",
       "      (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (w_v): Linear(in_features=128, out_features=1, bias=False)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embedding): Embedding(4581, 100)\n",
       "    (rnn): GRU(228, 128, num_layers=2, dropout=0.1)\n",
       "    (dense): Linear(in_features=128, out_features=4581, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3b5f28a-ec9c-4b3b-85ee-7b70c80d330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
    "    \n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = Timer()\n",
    "        metric = Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        print(f'epoch {epoch} loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "              f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcda25a2-bf87-4b4a-874c-ffc7c996ce50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.473, 54622.5 tokens/sec on cuda:0\n",
      "epoch 1 loss 0.352, 54548.2 tokens/sec on cuda:0\n",
      "epoch 2 loss 0.290, 54331.1 tokens/sec on cuda:0\n",
      "epoch 3 loss 0.247, 54878.1 tokens/sec on cuda:0\n",
      "epoch 4 loss 0.217, 55273.2 tokens/sec on cuda:0\n",
      "epoch 5 loss 0.194, 55305.3 tokens/sec on cuda:0\n",
      "epoch 6 loss 0.178, 54110.5 tokens/sec on cuda:0\n",
      "epoch 7 loss 0.164, 55230.0 tokens/sec on cuda:0\n",
      "epoch 8 loss 0.154, 55048.5 tokens/sec on cuda:0\n",
      "epoch 9 loss 0.145, 55441.6 tokens/sec on cuda:0\n",
      "epoch 10 loss 0.137, 55625.6 tokens/sec on cuda:0\n",
      "epoch 11 loss 0.131, 55383.3 tokens/sec on cuda:0\n",
      "epoch 12 loss 0.125, 55051.3 tokens/sec on cuda:0\n",
      "epoch 13 loss 0.121, 53920.6 tokens/sec on cuda:0\n",
      "epoch 14 loss 0.117, 54853.7 tokens/sec on cuda:0\n",
      "epoch 15 loss 0.113, 55092.7 tokens/sec on cuda:0\n",
      "epoch 16 loss 0.110, 54641.0 tokens/sec on cuda:0\n",
      "epoch 17 loss 0.107, 54876.7 tokens/sec on cuda:0\n",
      "epoch 18 loss 0.105, 55404.4 tokens/sec on cuda:0\n",
      "epoch 19 loss 0.103, 54162.2 tokens/sec on cuda:0\n",
      "epoch 20 loss 0.101, 55529.8 tokens/sec on cuda:0\n",
      "epoch 21 loss 0.099, 55236.3 tokens/sec on cuda:0\n",
      "epoch 22 loss 0.097, 54732.3 tokens/sec on cuda:0\n",
      "epoch 23 loss 0.096, 54483.2 tokens/sec on cuda:0\n",
      "epoch 24 loss 0.094, 54629.4 tokens/sec on cuda:0\n",
      "epoch 25 loss 0.093, 55542.8 tokens/sec on cuda:0\n",
      "epoch 26 loss 0.091, 54525.3 tokens/sec on cuda:0\n",
      "epoch 27 loss 0.090, 55459.5 tokens/sec on cuda:0\n",
      "epoch 28 loss 0.089, 54801.0 tokens/sec on cuda:0\n",
      "epoch 29 loss 0.088, 54419.6 tokens/sec on cuda:0\n",
      "epoch 30 loss 0.087, 55196.7 tokens/sec on cuda:0\n",
      "epoch 31 loss 0.086, 55138.7 tokens/sec on cuda:0\n",
      "epoch 32 loss 0.085, 54995.5 tokens/sec on cuda:0\n",
      "epoch 33 loss 0.085, 53845.6 tokens/sec on cuda:0\n",
      "epoch 34 loss 0.084, 54364.5 tokens/sec on cuda:0\n",
      "epoch 35 loss 0.083, 54851.3 tokens/sec on cuda:0\n",
      "epoch 36 loss 0.082, 54655.4 tokens/sec on cuda:0\n",
      "epoch 37 loss 0.082, 54701.5 tokens/sec on cuda:0\n",
      "epoch 38 loss 0.081, 55071.2 tokens/sec on cuda:0\n",
      "epoch 39 loss 0.081, 55155.4 tokens/sec on cuda:0\n",
      "epoch 40 loss 0.080, 54002.0 tokens/sec on cuda:0\n",
      "epoch 41 loss 0.080, 55148.4 tokens/sec on cuda:0\n",
      "epoch 42 loss 0.080, 54862.1 tokens/sec on cuda:0\n",
      "epoch 43 loss 0.078, 54472.4 tokens/sec on cuda:0\n",
      "epoch 44 loss 0.078, 54735.1 tokens/sec on cuda:0\n",
      "epoch 45 loss 0.078, 54809.7 tokens/sec on cuda:0\n",
      "epoch 46 loss 0.077, 54829.8 tokens/sec on cuda:0\n",
      "epoch 47 loss 0.077, 54135.1 tokens/sec on cuda:0\n",
      "epoch 48 loss 0.077, 55567.1 tokens/sec on cuda:0\n",
      "epoch 49 loss 0.076, 54925.3 tokens/sec on cuda:0\n",
      "epoch 50 loss 0.076, 54805.2 tokens/sec on cuda:0\n",
      "epoch 51 loss 0.076, 54390.2 tokens/sec on cuda:0\n",
      "epoch 52 loss 0.075, 54559.8 tokens/sec on cuda:0\n",
      "epoch 53 loss 0.075, 54690.6 tokens/sec on cuda:0\n",
      "epoch 54 loss 0.075, 53464.5 tokens/sec on cuda:0\n",
      "epoch 55 loss 0.075, 54887.8 tokens/sec on cuda:0\n",
      "epoch 56 loss 0.074, 54630.0 tokens/sec on cuda:0\n",
      "epoch 57 loss 0.074, 54405.1 tokens/sec on cuda:0\n",
      "epoch 58 loss 0.074, 55487.5 tokens/sec on cuda:0\n",
      "epoch 59 loss 0.073, 54862.1 tokens/sec on cuda:0\n",
      "epoch 60 loss 0.074, 55044.4 tokens/sec on cuda:0\n",
      "epoch 61 loss 0.073, 53457.7 tokens/sec on cuda:0\n",
      "epoch 62 loss 0.073, 55362.1 tokens/sec on cuda:0\n",
      "epoch 63 loss 0.073, 55100.0 tokens/sec on cuda:0\n",
      "epoch 64 loss 0.072, 54888.0 tokens/sec on cuda:0\n",
      "epoch 65 loss 0.072, 54605.9 tokens/sec on cuda:0\n",
      "epoch 66 loss 0.072, 54651.3 tokens/sec on cuda:0\n",
      "epoch 67 loss 0.072, 55102.9 tokens/sec on cuda:0\n",
      "epoch 68 loss 0.072, 54080.7 tokens/sec on cuda:0\n",
      "epoch 69 loss 0.071, 55222.2 tokens/sec on cuda:0\n",
      "epoch 70 loss 0.072, 54984.4 tokens/sec on cuda:0\n",
      "epoch 71 loss 0.071, 55196.2 tokens/sec on cuda:0\n",
      "epoch 72 loss 0.072, 55346.0 tokens/sec on cuda:0\n",
      "epoch 73 loss 0.071, 55473.7 tokens/sec on cuda:0\n",
      "epoch 74 loss 0.071, 55289.0 tokens/sec on cuda:0\n",
      "epoch 75 loss 0.071, 53317.3 tokens/sec on cuda:0\n",
      "epoch 76 loss 0.071, 54899.2 tokens/sec on cuda:0\n",
      "epoch 77 loss 0.071, 55136.9 tokens/sec on cuda:0\n",
      "epoch 78 loss 0.071, 55003.5 tokens/sec on cuda:0\n",
      "epoch 79 loss 0.070, 55433.0 tokens/sec on cuda:0\n",
      "epoch 80 loss 0.070, 55183.2 tokens/sec on cuda:0\n",
      "epoch 81 loss 0.070, 55005.8 tokens/sec on cuda:0\n",
      "epoch 82 loss 0.070, 53878.9 tokens/sec on cuda:0\n",
      "epoch 83 loss 0.070, 55054.7 tokens/sec on cuda:0\n",
      "epoch 84 loss 0.070, 55461.9 tokens/sec on cuda:0\n",
      "epoch 85 loss 0.070, 55185.7 tokens/sec on cuda:0\n",
      "epoch 86 loss 0.070, 55066.6 tokens/sec on cuda:0\n",
      "epoch 87 loss 0.070, 55116.3 tokens/sec on cuda:0\n",
      "epoch 88 loss 0.070, 54957.3 tokens/sec on cuda:0\n",
      "epoch 89 loss 0.069, 53693.9 tokens/sec on cuda:0\n",
      "epoch 90 loss 0.069, 54868.9 tokens/sec on cuda:0\n",
      "epoch 91 loss 0.070, 55183.4 tokens/sec on cuda:0\n",
      "epoch 92 loss 0.070, 55169.1 tokens/sec on cuda:0\n",
      "epoch 93 loss 0.069, 54651.9 tokens/sec on cuda:0\n",
      "epoch 94 loss 0.069, 54436.7 tokens/sec on cuda:0\n",
      "epoch 95 loss 0.069, 54957.5 tokens/sec on cuda:0\n",
      "epoch 96 loss 0.069, 54333.5 tokens/sec on cuda:0\n",
      "epoch 97 loss 0.069, 55194.7 tokens/sec on cuda:0\n",
      "epoch 98 loss 0.069, 55303.6 tokens/sec on cuda:0\n",
      "epoch 99 loss 0.069, 55109.6 tokens/sec on cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_seq2seq(net, dataloader, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd08df-5f7c-4a7a-b188-eea8120e5256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "415ea3f6-7b71-46b5-a72d-3eb0a5e85304",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdedb8-bf18-4c1e-8a25-c6b3713539b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da5a027b-a46e-4b8c-89d8-658f9b66e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
    "\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    # print(src_sentence)\n",
    "    words = list(jieba.cut(src_sentence))\n",
    "    # print(words)\n",
    "    \n",
    "    src_tokens = src_vocab[ words ] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    \n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4894b1-04d7-4dbc-b980-082f347bc813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f5de5-5591-471e-942d-944fd050ece1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a6c3f25-04ab-4caf-83db-a9843e4429cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨。 => hi .\n",
      "你好。 => hello .\n",
      "你用跑的。 => run to run .\n",
      "住手！ => stop !\n",
      "等等！ => wait !\n",
      "等一下！ => hang !\n",
      "开始！ => begin !\n",
      "你好。 => hello .\n",
      "我试试。 => i try .\n",
      "我赢了。 => i won !\n",
      "不会吧。 => oh no !\n",
      "干杯! => <unk> !\n",
      "知道了没有？ => do you know the way ?\n",
      "懂了吗？ => do you follow ?\n",
      "你懂了吗？ => do you have a good time ?\n",
      "他跑了。 => he ran .\n",
      "跳进来。 => the <unk> is on strike .\n",
      "我知道。 => i know .\n",
      "我退出。 => i quit .\n",
      "我不干了。 => i quit .\n",
      "我没事。 => i'm ok .\n",
      "我已经起来了。 => i've lost .\n",
      "听着。 => listen .\n",
      "不可能！ => no problem !\n",
      "没门！ => get out !\n",
      "你确定？ => are you sure ?\n",
      "谢谢！ => thanks !\n",
      "试试吧。 => try it .\n",
      "我们来试试。 => we try .\n",
      "为什么是我？ => why is that me ?\n",
      "去问汤姆。 => ask tom for .\n",
      "好棒！ => awesome !\n",
      "冷静点。 => cool down .\n",
      "公平点。 => be fair .\n",
      "友善点。 => be friendly .\n",
      "友好点。 => be friendly .\n",
      "和气点。 => take a look at the same .\n",
      "友善点。 => be friendly .\n",
      "联系我。 => call me .\n",
      "联系我们。 => call us .\n",
      "进来。 => come inside .\n",
      "找到汤姆。 => find tom .\n",
      "滚出去！ => get out !\n",
      "出去！ => go ! ! will hurry up .\n",
      "走开！ => go away !\n",
      "滚！ => get lost !\n",
      "走开！ => go away !\n",
      "回家。 => go home .\n",
      "回家吧。 => go home .\n",
      "再见！ => see you again .\n",
      "告辞！ => get out !\n",
      "坚持。 => keep it up .\n",
      "等一下！ => hang !\n",
      "坚持。 => keep it up .\n",
      "他来了。 => he came .\n",
      "他跑。 => he runs .\n",
      "帮我一下。 => help me .\n",
      "帮帮我们吧！ => help us .\n",
      "去打汤姆。 => go outside .\n",
      "坚持。 => keep it up .\n",
      "抱抱汤姆！ => hug tom .\n",
      "请抱紧汤姆。 => hug tom .\n",
      "我同意。 => i agree .\n",
      "我觉得很热。 => i think so night is very hot .\n",
      "我生病了。 => i'm ill .\n",
      "我很难过。 => i'm sad .\n",
      "我很害羞。 => i'm shy .\n",
      "我湿了。 => i'm wet .\n",
      "没关系。 => no problem .\n",
      "是我。 => that's me .\n",
      "来加入我们吧。 => join us .\n",
      "留着吧。 => keep it .\n",
      "吻我。 => kiss me .\n",
      "完美！ => perfect !\n",
      "再见！ => see you again .\n",
      "闭嘴！ => shut up !\n",
      "不管它。 => skip it .\n",
      "拿走吧。 => take it .\n",
      "告诉我！ => tell me .\n",
      "汤姆胜利了。 => tom was victorious .\n",
      "醒醒！ => wake up !\n",
      "去清洗一下。 => wash up .\n",
      "我们知道。 => we know that .\n",
      "欢迎。 => welcome .\n",
      "谁赢了？ => who won ?\n",
      "为什么不？ => why don't it quit ?\n",
      "你跑。 => you run .\n",
      "算你狠。 => you have to come .\n",
      "往后退点。 => back off !\n",
      "后退！ => back your time !\n",
      "往后退点。 => back off !\n",
      "静静的，别动。 => be also .\n",
      "我一无所知。 => i have no idea .\n",
      "把他铐上。 => put him on the shoulder .\n",
      "往前开。 => drive on .\n",
      "走开！ => go away !\n",
      "滚！ => get lost !\n",
      "趴下！ => get out !\n",
      "滚！ => get lost !\n",
      "滚。 => get lost !\n"
     ]
    }
   ],
   "source": [
    "num = 100\n",
    "for chn, eng in zip(chi_list[:num], eng_list[:num]):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, chn, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{chn} => {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ccd92d20-a6a8-437c-abc7-51df30ca5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汤姆试过还回泳衣来换成更大一号的，但是员工告诉他那是不被允许的。 => tom tried to return the <unk> for the past days\n",
      "在十九世纪三十年代的大萧条时期，许多富人在股市崩盘中失去了一切。 => during the depression in the <unk> , many wealthy people\n",
      "我觉得当汤姆发现他买来的画是赝品的时候，他会很生气。 => i think that tom is going to be pretty mad\n",
      "为了不被洪水冲走，有的人紧紧地抱着树干长达数个钟头。 => not some people like some tree , but even <unk>\n",
      "这个工人本来应该在中午十二点到达, 但他被交通堵塞困住了几个小时。 => the boy was divided before noon .\n",
      "我父母通常用法语对话，即使我母亲的母语是英语。 => my parents usually speak to each other in french ,\n",
      "就像马克·诺弗勒早期演唱的歌曲《金钱无用》一样，绝大多数的人依然高呼赞成“金钱无用论”。 => the <unk> was made of <unk> <unk> .\n",
      "假如你在老师讲课的时候再集中一点去听讲的话，你应该就能弄明白了。 => you'd better continue your wish more carefully .\n",
      "当汤姆开着他破旧的雷泽车来接女儿放学时，他的女儿假装不认识他。 => tom's daughter pretended not to get him to his daughter\n",
      "许多自然环境保护主义者担心持续屠杀鲸鱼正推动这些动物走向灭绝。 => a lot of <unk> fear .\n",
      "去年在菲律宾，地震和海啸造成了超过6000人的死亡。 => last people and in the beach last year , earthquakes\n",
      "“又是汤姆的电话？” “嗯。最近他每天晚上都会打过来。当时就不该给他我的号码的。” => \"is he calling tom ?\" \"i got married .\" \"i'll\n",
      "我母亲的法语比我父亲的英语要好，所以他们通常用法语交流。 => my mother speaks my best to speak english with french\n",
      "汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。 => tom is <unk> that he doesn't know how to translate\n",
      "汤姆不喜欢使用”有色人种“这个术语，因为他认为，根据这种说法白种人没有颜色。 => tom doesn't like to use an old dictionary to these\n",
      "你不想涂防晒霜是你的问题，但是晒伤了不要来抱怨。 => if you don't want to make a sunscreen on you\n",
      "即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。 => even now , i occasionally think i'd like to play\n",
      "你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。 => it's very easy to learn an end to mary natural\n",
      "虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。 => i was tired since i was very <unk> .\n",
      "如果一个人在成人前没有机会习得目标语言，他对该语言的认识达到母语者程度的机会是相当小的。 => there was a person chance of a chance to <unk>\n"
     ]
    }
   ],
   "source": [
    "num = -20\n",
    "for chn, eng in zip(chi_list[num:], eng_list[num:]):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, chn, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{chn} => {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e5d4c-f34a-4af9-9dda-464a95ab4758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf0ebadb-5a2b-45b1-8d1c-fcf82ffba920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我要去上学=>i go to school .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我要去上学\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69dedbc1-6843-4501-ae83-a4ad300886c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多可爱啊！=>how cute !\n"
     ]
    }
   ],
   "source": [
    "sentence = \"多可爱啊！\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e53d6db7-646c-47a5-86b0-d7a008f02d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抓住他=>grab him .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"抓住他\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0499da62-650f-4d95-a821-a793c58d797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名律师=>i'm a lawyer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名律师\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5cda0329-3e2c-4a1a-9b44-ce61d99ebff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名程序员=>i'm a computer programmer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名程序员\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f44e4ffb-0ae1-4a9a-808a-97b0aa3590f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名飞行员=>i'm a professional of brave .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名飞行员\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d9e3a-86b7-4db2-aae8-474ce47572dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cbb07-1d6a-4c93-afbe-7f02f4d52aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702efe4-58d0-419f-8ee2-476d5f5c1fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9977204d-913f-4310-9917-db78b240bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我在踢足球=>i stay in bed .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我在踢足球\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb1aa00c-ade6-477a-b689-ec210c0ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我在飞=>i'm on a foreigner .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我在飞\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaf9f6-8f45-49fb-b28b-eac2f35b2f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf9b4f-261f-4349-ba68-61470cc5771f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923167a-73c9-4568-a860-56bc3bff5747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f617e-f853-4e98-9ca3-f09ad8f09a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5c98e-18c5-4842-a115-3a1244b8dc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b465cc7-9e93-49dc-aba7-545a35afd936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596655d2-4c32-4602-b90b-b6bc8af75fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18d958-6a13-48e2-a0d3-84b44fb1809c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d66a3a-35f2-4e68-a48e-3376c3462f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620b6e5-e18b-4c82-9d87-cb435d423fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64801c-bc89-44b4-ae34-0aa7e1951bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff23092-9bc6-448b-9174-554149a30b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82627b04-cf13-40ab-8351-b1676a189627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e73c28-d2d4-4da0-8204-a024f90c86bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
