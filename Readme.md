#### 注意力机制

[注意力机制-动手学深度学习](https://zh.d2l.ai/chapter_attention-mechanisms/bahdanau-attention.html)

1. case-1: Esim: 短文本相似度

2. case-2: mt_seq2seq_with_attention, BiLSTM + attention

3. case-3: mt_transformer, 翻译效果明显好于 case-2
