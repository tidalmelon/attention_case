{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9842226a-3ba5-4ad1-ac1f-1d1f90ed9db1",
   "metadata": {},
   "source": [
    "[machine translation corpus](https://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547b052d-ed8e-41bc-8bad-47ce415f0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-10 13:42:03--  https://www.manythings.org/anki/cmn-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1270861 (1.2M) [application/zip]\n",
      "Saving to: ‘./data/cmn-eng.zip’\n",
      "\n",
      "cmn-eng.zip         100%[===================>]   1.21M   766KB/s    in 1.6s    \n",
      "\n",
      "2023-02-10 13:42:05 (766 KB/s) - ‘./data/cmn-eng.zip’ saved [1270861/1270861]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/cmn-eng.zip -P ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ded6150-4ff8-4c49-9148-237bdbbf1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./data/cmn-eng.zip\n",
      "  inflating: ./data/cmn.txt          \n",
      "  inflating: ./data/_about.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip ./data/cmn-eng.zip -d ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbb38de-f4cd-4b84-91ed-9912a904542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import zhconv\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd512008-e9ec-4f2a-81c2-28e4b4fa28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./codes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376cece3-050e-4e1c-90e6-0715dfaed3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770662b6-bb78-470d-8d10-4b4c6abe8fa3",
   "metadata": {},
   "source": [
    "## load corpus\n",
    "\n",
    "load sentences pair in chinese and english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7497ff0a-b501-4b44-ba95-013b0b87e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    chi_list = []\n",
    "    eng_list = []\n",
    "    with open('./data/cmn.txt') as f:\n",
    "        for line in f:\n",
    "            eng_sent, chi_sent, _ = line.split('\\t')\n",
    "            \n",
    "            # traditional to simplified\n",
    "            # zhconv.convert('走開！', 'zh-cn')\n",
    "            chi_sent = zhconv.convert(chi_sent, 'zh-cn')\n",
    "            \n",
    "            chi_list.append(chi_sent)\n",
    "            eng_list.append(eng_sent)\n",
    "    return chi_list, eng_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7824679-dab3-4e28-a3ce-54fb294f53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_list, eng_list = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa14d69-65cd-4c6f-b1b0-e31fc503ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('嗨。', 'Hi.'), ('你好。', 'Hi.'), ('你用跑的。', 'Run.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chi_list[:3], eng_list[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41435a34-f49c-4fe0-826d-7146916d2ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。',\n",
       "  \"It's very easy to sound natural in your own native language, and very easy to sound unnatural in your non-native language.\"),\n",
       " ('虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。',\n",
       "  \"I got fired from the company, but since I have a little money saved up, for the time being, I won't have trouble with living expenses.\"),\n",
       " ('如果一个人在成人前没有机会习得目标语言，他对该语言的认识达到母语者程度的机会是相当小的。',\n",
       "  \"If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(chi_list[-3:], eng_list[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a166472-e708-42f5-aeba-f536bd8b436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26a797-874f-4f22-a8f4-48d4e7cfd8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5ad6f-e3d7-468d-ace6-2dddffedf2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "330ac668-9e45-44d5-9e76-3f875583b513",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d815a95-608f-40de-882a-ab108ffa3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_space(word):\n",
    "    if not word:\n",
    "        # None ''\n",
    "        return True\n",
    "    if word.isspace():\n",
    "        #\\t \\n \\r \\u202f \\xa0\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a34d7f-f0cd-40bd-88e4-ec1ec2b6e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'recommend', 'item']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['', ' ', 'i' , 'recommend', 'item']\n",
    "[w for w in words if not is_space(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2e0128-da1d-4fce-b4f3-895263fb3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_space(text):\n",
    "    # for english only\n",
    "    # fill space before ,.!? which is convenient to tokenize\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "    \n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9da2b81-3a20-467b-b338-ed6afac5e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's very easy to sound natural in your own native language , and very easy to sound unnatural in your non-native language .\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_space(\"It's very easy to sound natural in your own native language, and very easy to sound unnatural in your non-native language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef7edb1-1472-42f2-a316-f41586273227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(chi_list, eng_list):\n",
    "    \n",
    "    source = []\n",
    "    for sent in chi_list:\n",
    "        words = jieba.cut(sent)\n",
    "        words = [w for w in words if not is_space(w)]\n",
    "        source.append(words)\n",
    "        \n",
    "    target = []\n",
    "    for sent in eng_list:\n",
    "        sent = sent.lower()\n",
    "        sent = fill_space(sent)\n",
    "        words = sent.split(' ')\n",
    "        words = [w for w in words if not is_space(w)]\n",
    "        target.append(words)\n",
    "        \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16f665-6ebd-4a77-9e0d-c158d914e088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a208996-08cd-40c9-b595-f28d6e862e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.399 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "source, target = tokenize(chi_list, eng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fc62f12-8759-4dbd-ab1a-09582efa2c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['嗨', '。'], ['你好', '。'], ['你', '用', '跑', '的', '。'], ['住手', '！'], ['等等', '！']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c83258e-851c-4414-b770-28bc90ba45b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi', '.'], ['hi', '.'], ['run', '.'], ['stop', '!'], ['wait', '!']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824053e-2c46-4f44-97a6-5afd13130a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "757d22e3-c462-4477-b281-6075826b793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for sent_cn, sent_eng in zip(source, target):\n",
    "    arr.append([len(sent_cn), len(sent_eng)])\n",
    "arr = torch.tensor(arr, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2e8c39-d8f5-4376-b6cf-3f66eeb94aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([30., 34.]),\n",
       "indices=tensor([29362, 29370]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8270e1bf-49cb-43c6-97c6-4c6e2b5c6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6265, 7.2073])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4667d443-2d4b-4a35-a994-f72c384daa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_steps = 10, is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e81de-abcf-496f-93a8-4b2793ef892e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2cda031-f9be-4cff-baf9-023fdfb53882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    \"\"\"vocabulary\"\"\"\n",
    "    \n",
    "    def __init__(self, tokens, min_freq=0, reserved_tokens=['<pad>', '<bos>', '<eos>']):\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        self._token_freqs = sorted(Counter(tokens).items(), key=lambda x: x[1], reverse=True)\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}\n",
    "        \n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) -1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token(indices)\n",
    "        return [self.idx_to_token[indice] for indice in indices]\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        # index for the unknown token\n",
    "        return 0\n",
    "    \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b02c83d-40dd-41b7-a73e-51a30034e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d28d7a13-3046-46d9-aedd-b31cb703cd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['<pad>'], src_vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f80c0a70-4f49-4aad-b6da-0b039748d19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab[['<unk>', '<pad>', '<bos>', '<eos>', '。']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fabd49-a2ad-40f4-8877-ca3482497e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4feda06-9719-4549-9cb5-e672b474ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"truncate or pad sequence\"\"\"\n",
    "    if len(line) > num_steps: \n",
    "        # trancate\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token] * (num_steps - len(line)) # pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d532bd26-d5b1-4ffe-a6bb-899e1c6bde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(lines, vocab, num_steps):\n",
    "    \"\"\"transfrom text sequence of machine traslation into minibatches.\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    arr = [ truncate_pad(l, num_steps, vocab['<pad>'])  for l in lines]\n",
    "    arr = torch.tensor(arr)\n",
    "    \n",
    "    valid_len = (arr != vocab['<pad>']).type(torch.int32).sum(dim=1)\n",
    "    \n",
    "    return arr, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28d543ff-8c93-4b55-9f07-a1de1afb8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 128, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0aa0af1-7303-4493-bec2-3067dc5da8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_arr, src_valid_len = to_tensor(source, src_vocab, num_steps=num_steps)\n",
    "tgt_arr, tgt_valid_len = to_tensor(target, tgt_vocab, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44aa2e84-ed15-4219-9e7b-40d7aea7a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2500,    4,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1210,    4,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [   8,  112,  324,    6,    4,    3,    1,    1,    1,    1],\n",
       "         [4522,   72,    3,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [2501,   72,    3,    1,    1,    1,    1,    1,    1,    1]]),\n",
       " tensor([3, 3, 6, 3, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_arr[:5], src_valid_len[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a33b7002-3f5c-4f23-b6c2-e02f7650dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataloader(arr_list, batch_size, is_train=True):\n",
    "    dataset = TensorDataset(*arr_list)\n",
    "    return DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9159b013-ddf8-4671-ac1d-46249be26145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 3, 6, 3, 3]), tensor([10, 10, 10, 10, 10]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_valid_len[:5], src_valid_len[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12444e67-2571-49fe-a461-466038cb7604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a55f91a-4214-4228-b65e-06691ae1a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = to_dataloader((src_arr, src_valid_len, tgt_arr, tgt_valid_len), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "489252a7-c6a8-4264-a9af-d85de0510f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10]) torch.Size([128]) torch.Size([128, 10]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for e in iter(dataloader):\n",
    "    print(e[0].shape, e[1].shape, e[2].shape, e[3].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb50a0-1fd6-4dbb-874f-5813e612fda1",
   "metadata": {},
   "source": [
    "## seq2seq with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f6cac17-9c8d-4d29-9185-38e37d3e86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(common.Encoder):\n",
    "    \"\"\"The RNN encoder for sequence to sequence learning.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq`\"\"\"\n",
    "    # encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
    "        X = self.embedding(X)\n",
    "        # In RNN models, the first axis corresponds to time steps\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # When state is not mentioned, it defaults to zeros\n",
    "        output, state = self.rnn(X)\n",
    "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86475504-f3cf-4f5f-a5e4-55380ea5eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(common.AttentionDecoder):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.attention = common.AdditiveAttention(num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size+num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "        \n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # encodet output:\n",
    "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        \n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "    \n",
    "        # return:\n",
    "        # outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "        # hidden_state.shape = [num_layers，batch_size，num_hiddens]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        # X.shape = [batch_size, num_steps]\n",
    "        \n",
    "        # return:\n",
    "        # enc_outputs = outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "        # hidden_state.shape = [num_layers，batch_size，num_hiddens]\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        \n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        # X.embedding.shape = [batch_size, num_steps, embed_size]\n",
    "        # X.shape = [num_steps, batch_size, embed_size]\n",
    "        \n",
    "        outputs, self._attention_weights = [], []\n",
    "        \n",
    "        # iterate num_steps or words:\n",
    "        for x in X:\n",
    "            # x.shape = [batch_size, embed_size]\n",
    "            \n",
    "            # hidden_state[-1].shape = [batch_size, num_hiddens] , alwasys only use the finnal layrers hidden_state\n",
    "            # unsqueeze.shape = [batch_size, 1, num_hiddens]\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # query.shape = [batch_size, 1, num_hiddens]\n",
    "            \n",
    "            # additive attention API:\n",
    "            # forward(self, queries, keys, values, valid_lens):\n",
    "            # queries = [batch_size, 查询的个数, 查询的维度] = [batch_size, num_queries, q]\n",
    "            # keys = [batch_size, “键－值”对的个数, 键的维度] = [batch_size, num_keys, k]\n",
    "            # values = [batch_size, “键－值”对的个数, 值得维度]\n",
    "            \n",
    "            # query.shape = [batch_size, num_steps(num_words), num_hiddens]\n",
    "            # query.shape = [batch_size, 1, num_hiddens]\n",
    "            # enc_outputs = keys = outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "            # enc_outputs =values = outputs.shape = [batch_size，num_steps，num_hiddens]\n",
    "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # context.shape = : 加权平均weight_mean = [batch_size, 查询的个数, 值的维度)\n",
    "            # context.shape = : 加权平均weight_mean = [batch_size, 1, num_hiddens)\n",
    "            \n",
    "            # x.unsqueeze.shape = [batch_size, 1, embed_size]\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1) # cat on the last dim\n",
    "            # x.shape = [batch_size, 1, embed_size+num_hiddens]\n",
    "            \n",
    "            # x.permute.shape = [1, batch_size, embed_size+num_hiddens]\n",
    "            # GRU.input.shape = [seq_len(num_steps, word_len), batch_size, num_hiddens=embed_size+num_hiddens] 符合预期\n",
    "            \n",
    "            # hidden_state.shape = [num_layers，batch_size，num_hiddens]\n",
    "            # GRU.h_0.shape = [number_layers, batch_size, num_hiddens]  符合预期，这个不需要cat拼接\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            # out.shape = [num_steps, batch_size, num_hiddens]  见下图， rnn 将x_t(embed_size+num_hiddens) 与 h_t-1 合并为 num_hiddens\n",
    "            # 注意哦，RNN的输入包含了Linear的in_features, 也包含Linear.out_features也是Linear的输入\n",
    "            # hidden_state = [num_layers, batch_size, num_hiddens=hidden_size]\n",
    "           \n",
    "            outputs.append(out)\n",
    "            # [ inner.shape = num_steps, batch_size, num_hiddens ] 经RNN合并后的num_hiddens\n",
    "            \n",
    "            \n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "            \n",
    "        # definition: dense = nn.Linear(num_hiddens, vocab_size)\n",
    "        # outpus.cat.shape = out.shape = [num_steps, batch_size, num_hiddens] 经RNN合并后的num_hiddens, 符合预期\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0)) # dim=0, 列叠加\n",
    "        # outputs.shape = [num_steps,batch_size,vocab_size], 符合预期 \n",
    "        \n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state, enc_valid_lens]\n",
    "        # outputs.shape = [batch_size, num_steps, vocab_size]\n",
    "        # enc_outputs = encoder_outputs keep it's value from encoder layer\n",
    "        # hidden_state.shape = [num_layers，batch_size，num_hiddens],   hidden_state keep it's shape, and it's values are updated\n",
    "    \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "067bfb10-fa07-42af-b3ff-e7e8a0e5b8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4581"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26efac52-def5-4233-b296-f2e8b88e6177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6537"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe691f-09b2-4c1f-9053-39e3f6efc79f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83a0f8d5-ad7e-47e5-91d0-6a3550c99c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_steps = 10\n",
    "lr = 0.005\n",
    "num_epochs = 100\n",
    "\n",
    "# embed_size = 32\n",
    "embed_size = 100\n",
    "num_hiddens = 128\n",
    "num_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "device = common.try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "491b8617-1f3f-4e18-a177-9ca1c42d5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d399161-9b40-4177-a60a-78b19049a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = common.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "637d1e6e-70a8-4987-80e0-960fe3bc2b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Seq2SeqEncoder(\n",
       "    (embedding): Embedding(6537, 100)\n",
       "    (rnn): GRU(100, 128, num_layers=2, dropout=0.1)\n",
       "  )\n",
       "  (decoder): Seq2SeqAttentionDecoder(\n",
       "    (attention): AdditiveAttention(\n",
       "      (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (w_v): Linear(in_features=128, out_features=1, bias=False)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embedding): Embedding(4581, 100)\n",
       "    (rnn): GRU(228, 128, num_layers=2, dropout=0.1)\n",
       "    (dense): Linear(in_features=128, out_features=4581, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3b5f28a-ec9c-4b3b-85ee-7b70c80d330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
    "    \n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = common.MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = common.Timer()\n",
    "        metric = common.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            common.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        print(f'epoch {epoch} loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "              f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcda25a2-bf87-4b4a-874c-ffc7c996ce50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.461, 54200.5 tokens/sec on cuda:0\n",
      "epoch 1 loss 0.335, 55311.1 tokens/sec on cuda:0\n",
      "epoch 2 loss 0.279, 54588.8 tokens/sec on cuda:0\n",
      "epoch 3 loss 0.241, 54337.8 tokens/sec on cuda:0\n",
      "epoch 4 loss 0.213, 54184.8 tokens/sec on cuda:0\n",
      "epoch 5 loss 0.192, 55032.6 tokens/sec on cuda:0\n",
      "epoch 6 loss 0.175, 55538.8 tokens/sec on cuda:0\n",
      "epoch 7 loss 0.162, 55009.0 tokens/sec on cuda:0\n",
      "epoch 8 loss 0.152, 55668.4 tokens/sec on cuda:0\n",
      "epoch 9 loss 0.143, 55238.8 tokens/sec on cuda:0\n",
      "epoch 10 loss 0.135, 55266.0 tokens/sec on cuda:0\n",
      "epoch 11 loss 0.129, 55699.7 tokens/sec on cuda:0\n",
      "epoch 12 loss 0.124, 54570.1 tokens/sec on cuda:0\n",
      "epoch 13 loss 0.119, 55300.8 tokens/sec on cuda:0\n",
      "epoch 14 loss 0.115, 55349.9 tokens/sec on cuda:0\n",
      "epoch 15 loss 0.112, 55693.7 tokens/sec on cuda:0\n",
      "epoch 16 loss 0.108, 54821.9 tokens/sec on cuda:0\n",
      "epoch 17 loss 0.105, 54805.8 tokens/sec on cuda:0\n",
      "epoch 18 loss 0.103, 55064.3 tokens/sec on cuda:0\n",
      "epoch 19 loss 0.101, 54940.6 tokens/sec on cuda:0\n",
      "epoch 20 loss 0.099, 54442.2 tokens/sec on cuda:0\n",
      "epoch 21 loss 0.097, 53365.2 tokens/sec on cuda:0\n",
      "epoch 22 loss 0.095, 54174.3 tokens/sec on cuda:0\n",
      "epoch 23 loss 0.094, 54668.6 tokens/sec on cuda:0\n",
      "epoch 24 loss 0.092, 55407.5 tokens/sec on cuda:0\n",
      "epoch 25 loss 0.091, 55255.5 tokens/sec on cuda:0\n",
      "epoch 26 loss 0.090, 54591.9 tokens/sec on cuda:0\n",
      "epoch 27 loss 0.088, 54601.3 tokens/sec on cuda:0\n",
      "epoch 28 loss 0.087, 55252.0 tokens/sec on cuda:0\n",
      "epoch 29 loss 0.087, 55282.0 tokens/sec on cuda:0\n",
      "epoch 30 loss 0.085, 54556.3 tokens/sec on cuda:0\n",
      "epoch 31 loss 0.084, 55505.0 tokens/sec on cuda:0\n",
      "epoch 32 loss 0.084, 55635.9 tokens/sec on cuda:0\n",
      "epoch 33 loss 0.083, 55408.1 tokens/sec on cuda:0\n",
      "epoch 34 loss 0.082, 55372.0 tokens/sec on cuda:0\n",
      "epoch 35 loss 0.081, 54927.4 tokens/sec on cuda:0\n",
      "epoch 36 loss 0.081, 55373.7 tokens/sec on cuda:0\n",
      "epoch 37 loss 0.080, 55394.7 tokens/sec on cuda:0\n",
      "epoch 38 loss 0.080, 55617.4 tokens/sec on cuda:0\n",
      "epoch 39 loss 0.079, 55090.1 tokens/sec on cuda:0\n",
      "epoch 40 loss 0.079, 54163.1 tokens/sec on cuda:0\n",
      "epoch 41 loss 0.078, 55254.9 tokens/sec on cuda:0\n",
      "epoch 42 loss 0.078, 54926.2 tokens/sec on cuda:0\n",
      "epoch 43 loss 0.078, 54913.8 tokens/sec on cuda:0\n",
      "epoch 44 loss 0.077, 54315.0 tokens/sec on cuda:0\n",
      "epoch 45 loss 0.076, 54982.8 tokens/sec on cuda:0\n",
      "epoch 46 loss 0.076, 54945.1 tokens/sec on cuda:0\n",
      "epoch 47 loss 0.076, 55111.5 tokens/sec on cuda:0\n",
      "epoch 48 loss 0.076, 55536.2 tokens/sec on cuda:0\n",
      "epoch 49 loss 0.075, 54349.9 tokens/sec on cuda:0\n",
      "epoch 50 loss 0.075, 54483.7 tokens/sec on cuda:0\n",
      "epoch 51 loss 0.075, 54828.6 tokens/sec on cuda:0\n",
      "epoch 52 loss 0.074, 54557.5 tokens/sec on cuda:0\n",
      "epoch 53 loss 0.074, 55287.4 tokens/sec on cuda:0\n",
      "epoch 54 loss 0.074, 54351.9 tokens/sec on cuda:0\n",
      "epoch 55 loss 0.074, 54760.5 tokens/sec on cuda:0\n",
      "epoch 56 loss 0.073, 55101.4 tokens/sec on cuda:0\n",
      "epoch 57 loss 0.073, 55548.9 tokens/sec on cuda:0\n",
      "epoch 58 loss 0.073, 54878.7 tokens/sec on cuda:0\n",
      "epoch 59 loss 0.073, 55233.1 tokens/sec on cuda:0\n",
      "epoch 60 loss 0.072, 55498.2 tokens/sec on cuda:0\n",
      "epoch 61 loss 0.072, 55503.8 tokens/sec on cuda:0\n",
      "epoch 62 loss 0.072, 55297.2 tokens/sec on cuda:0\n",
      "epoch 63 loss 0.072, 54301.9 tokens/sec on cuda:0\n",
      "epoch 64 loss 0.072, 54803.7 tokens/sec on cuda:0\n",
      "epoch 65 loss 0.072, 54784.1 tokens/sec on cuda:0\n",
      "epoch 66 loss 0.072, 54769.1 tokens/sec on cuda:0\n",
      "epoch 67 loss 0.071, 54927.4 tokens/sec on cuda:0\n",
      "epoch 68 loss 0.071, 53848.5 tokens/sec on cuda:0\n",
      "epoch 69 loss 0.071, 55425.8 tokens/sec on cuda:0\n",
      "epoch 70 loss 0.071, 55393.3 tokens/sec on cuda:0\n",
      "epoch 71 loss 0.071, 55649.8 tokens/sec on cuda:0\n",
      "epoch 72 loss 0.070, 54724.1 tokens/sec on cuda:0\n",
      "epoch 73 loss 0.070, 54871.1 tokens/sec on cuda:0\n",
      "epoch 74 loss 0.070, 55081.1 tokens/sec on cuda:0\n",
      "epoch 75 loss 0.070, 55218.5 tokens/sec on cuda:0\n",
      "epoch 76 loss 0.070, 55062.7 tokens/sec on cuda:0\n",
      "epoch 77 loss 0.070, 54537.9 tokens/sec on cuda:0\n",
      "epoch 78 loss 0.070, 55083.0 tokens/sec on cuda:0\n",
      "epoch 79 loss 0.070, 54619.9 tokens/sec on cuda:0\n",
      "epoch 80 loss 0.070, 54695.8 tokens/sec on cuda:0\n",
      "epoch 81 loss 0.070, 55054.0 tokens/sec on cuda:0\n",
      "epoch 82 loss 0.070, 54214.1 tokens/sec on cuda:0\n",
      "epoch 83 loss 0.070, 55123.8 tokens/sec on cuda:0\n",
      "epoch 84 loss 0.069, 55091.6 tokens/sec on cuda:0\n",
      "epoch 85 loss 0.070, 54843.7 tokens/sec on cuda:0\n",
      "epoch 86 loss 0.070, 54131.1 tokens/sec on cuda:0\n",
      "epoch 87 loss 0.069, 54386.3 tokens/sec on cuda:0\n",
      "epoch 88 loss 0.070, 55412.6 tokens/sec on cuda:0\n",
      "epoch 89 loss 0.070, 55693.5 tokens/sec on cuda:0\n",
      "epoch 90 loss 0.070, 55505.4 tokens/sec on cuda:0\n",
      "epoch 91 loss 0.070, 54307.5 tokens/sec on cuda:0\n",
      "epoch 92 loss 0.069, 55166.0 tokens/sec on cuda:0\n",
      "epoch 93 loss 0.070, 54882.1 tokens/sec on cuda:0\n",
      "epoch 94 loss 0.069, 54821.5 tokens/sec on cuda:0\n",
      "epoch 95 loss 0.069, 54917.8 tokens/sec on cuda:0\n",
      "epoch 96 loss 0.069, 54292.8 tokens/sec on cuda:0\n",
      "epoch 97 loss 0.069, 55086.3 tokens/sec on cuda:0\n",
      "epoch 98 loss 0.069, 55173.0 tokens/sec on cuda:0\n",
      "epoch 99 loss 0.069, 55308.3 tokens/sec on cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_seq2seq(net, dataloader, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd08df-5f7c-4a7a-b188-eea8120e5256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "415ea3f6-7b71-46b5-a72d-3eb0a5e85304",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdedb8-bf18-4c1e-8a25-c6b3713539b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da5a027b-a46e-4b8c-89d8-658f9b66e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
    "\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    # print(src_sentence)\n",
    "    words = list(jieba.cut(src_sentence))\n",
    "    # print(words)\n",
    "    \n",
    "    src_tokens = src_vocab[ words ] + [src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    \n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4894b1-04d7-4dbc-b980-082f347bc813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f5de5-5591-471e-942d-944fd050ece1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a6c3f25-04ab-4caf-83db-a9843e4429cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嗨。 => hi .\n",
      "你好。 => hello !\n",
      "你用跑的。 => run on you .\n",
      "住手！ => stop !\n",
      "等等！ => wait !\n",
      "等一下！ => wait !\n",
      "开始！ => begin .\n",
      "你好。 => hello !\n",
      "我试试。 => i try .\n",
      "我赢了。 => i won .\n",
      "不会吧。 => oh no !\n",
      "干杯! => <unk> !\n",
      "知道了没有？ => has know that ?\n",
      "懂了吗？ => did you try ?\n",
      "你懂了吗？ => did you understand ?\n",
      "他跑了。 => he ran out .\n",
      "跳进来。 => constant dripping wears away a stone .\n",
      "我知道。 => i know .\n",
      "我退出。 => i quit .\n",
      "我不干了。 => i don't have no hero .\n",
      "我没事。 => i am okay .\n",
      "我已经起来了。 => i'm already missing .\n",
      "听着。 => listen is cold .\n",
      "不可能！ => no way !\n",
      "没门！ => open fire !\n",
      "你确定？ => are you sure ?\n",
      "谢谢！ => thanks !\n",
      "试试吧。 => try it .\n",
      "我们来试试。 => let's try it .\n",
      "为什么是我？ => why ?\n",
      "去问汤姆。 => ask tom .\n",
      "好棒！ => fantastic !\n",
      "冷静点。 => cool down .\n",
      "公平点。 => be fair .\n",
      "友善点。 => be nice .\n",
      "友好点。 => be kind .\n",
      "和气点。 => <unk> with a step .\n",
      "友善点。 => be nice .\n",
      "联系我。 => call me .\n",
      "联系我们。 => call us .\n",
      "进来。 => step inside .\n",
      "找到汤姆。 => ask tom .\n",
      "滚出去！ => open fire !\n",
      "出去！ => go out !\n",
      "走开！ => go away !\n",
      "滚！ => get away !\n",
      "走开！ => go away !\n",
      "回家。 => go home at home .\n",
      "回家吧。 => go home .\n",
      "再见！ => goodbye !\n",
      "告辞！ => open fire !\n",
      "坚持。 => hang on .\n",
      "等一下！ => wait !\n",
      "坚持。 => hang on .\n",
      "他来了。 => he came .\n",
      "他跑。 => he runs .\n",
      "帮我一下。 => help me .\n",
      "帮帮我们吧！ => let's go away .\n",
      "去打汤姆。 => hit tom .\n",
      "坚持。 => hang on .\n",
      "抱抱汤姆！ => hug tom .\n",
      "请抱紧汤姆。 => hug tom .\n",
      "我同意。 => i agree with that .\n",
      "我觉得很热。 => i'm hot .\n",
      "我生病了。 => i'm sick .\n",
      "我很难过。 => i'm sad .\n",
      "我很害羞。 => i was shy .\n",
      "我湿了。 => i'm wet .\n",
      "没关系。 => it's ok .\n",
      "是我。 => i'm a liar .\n",
      "来加入我们吧。 => join us .\n",
      "留着吧。 => keep it .\n",
      "吻我。 => kiss me .\n",
      "完美！ => perfect !\n",
      "再见！ => goodbye !\n",
      "闭嘴！ => shut !\n",
      "不管它。 => skip no point .\n",
      "拿走吧。 => take it .\n",
      "告诉我！ => tell me .\n",
      "汤姆胜利了。 => tom won .\n",
      "醒醒！ => wake up !\n",
      "去清洗一下。 => wash wash your head .\n",
      "我们知道。 => we know .\n",
      "欢迎。 => welcome .\n",
      "谁赢了？ => who won ?\n",
      "为什么不？ => why don't you ?\n",
      "你跑。 => you're not .\n",
      "算你狠。 => you win .\n",
      "往后退点。 => back off .\n",
      "后退！ => back !\n",
      "往后退点。 => back off .\n",
      "静静的，别动。 => a little hope is not done .\n",
      "我一无所知。 => i have no idea .\n",
      "把他铐上。 => put him on the wall .\n",
      "往前开。 => drive away .\n",
      "走开！ => go away !\n",
      "滚！ => get away !\n",
      "趴下！ => open fire !\n",
      "滚！ => get away !\n",
      "滚。 => get lost .\n"
     ]
    }
   ],
   "source": [
    "num = 100\n",
    "for chn, eng in zip(chi_list[:num], eng_list[:num]):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, chn, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{chn} => {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccd92d20-a6a8-437c-abc7-51df30ca5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汤姆试过还回泳衣来换成更大一号的，但是员工告诉他那是不被允许的。 => tom tried to return a back to the company in\n",
      "在十九世纪三十年代的大萧条时期，许多富人在股市崩盘中失去了一切。 => during the depression , but in many wealthy people grew\n",
      "我觉得当汤姆发现他买来的画是赝品的时候，他会很生气。 => i think tom is going to be pretty mad when\n",
      "为了不被洪水冲走，有的人紧紧地抱着树干长达数个钟头。 => some people be <unk> for several hours to tree in\n",
      "这个工人本来应该在中午十二点到达, 但他被交通堵塞困住了几个小时。 => the <unk> was supposed to arrive at twelve noon ,\n",
      "我父母通常用法语对话，即使我母亲的母语是英语。 => my parents usually speak to french in french , and\n",
      "就像马克·诺弗勒早期演唱的歌曲《金钱无用》一样，绝大多数的人依然高呼赞成“金钱无用论”。 => the great crowd <unk> as mark <unk> <unk> the air\n",
      "假如你在老师讲课的时候再集中一点去听讲的话，你应该就能弄明白了。 => if you are a little taller until the lake is\n",
      "当汤姆开着他破旧的雷泽车来接女儿放学时，他的女儿假装不认识他。 => tom's daughter pretended not to know him when he had\n",
      "许多自然环境保护主义者担心持续屠杀鲸鱼正推动这些动物走向灭绝。 => a great <unk> company are <unk> of whales <unk> <unk>\n",
      "去年在菲律宾，地震和海啸造成了超过6000人的死亡。 => last year was <unk> in a small train will arrive\n",
      "“又是汤姆的电话？” “嗯。最近他每天晚上都会打过来。当时就不该给他我的号码的。” => <unk> one , what is the <unk> <unk> .\" <unk>\n",
      "我母亲的法语比我父亲的英语要好，所以他们通常用法语交流。 => my mother speaks french weather as a common french as\n",
      "汤姆不知如何翻译“计算机”一词，因为同他谈话的人从未见过一台。 => tom doesn't know how to translate this <unk> <unk> and\n",
      "汤姆不喜欢使用”有色人种“这个术语，因为他认为，根据这种说法白种人没有颜色。 => tom doesn't like to use the term \"a person of\n",
      "你不想涂防晒霜是你的问题，但是晒伤了不要来抱怨。 => if you want to pay more paper if you want\n",
      "即使是现在，我偶尔还是想见到你。不是今天的你，而是我记忆中曾经的你。 => i occasionally miss me for ages .\n",
      "你很容易把母语说得通顺流畅，却很容易把非母语说得不自然。 => you're the kind of the <unk> , deaf on the\n",
      "虽然我被公司解雇了，但是我还有点存款，所以目前不用担心生计问题。 => since i was fired from the company , but since\n",
      "如果一个人在成人前没有机会习得目标语言，他对该语言的认识达到母语者程度的机会是相当小的。 => if a man would not have been a <unk> hour\n"
     ]
    }
   ],
   "source": [
    "num = -20\n",
    "for chn, eng in zip(chi_list[num:], eng_list[num:]):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, chn, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{chn} => {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e5d4c-f34a-4af9-9dda-464a95ab4758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69dedbc1-6843-4501-ae83-a4ad300886c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多可爱啊！=>how lovely !\n"
     ]
    }
   ],
   "source": [
    "sentence = \"多可爱啊！\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e53d6db7-646c-47a5-86b0-d7a008f02d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抓住他=>grab him .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"抓住他\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0499da62-650f-4d95-a821-a793c58d797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名律师=>i'm a lawyer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名律师\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9977204d-913f-4310-9917-db78b240bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我在踢足球=>i play soccer .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我在踢足球\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d9e3a-86b7-4db2-aae8-474ce47572dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cbb07-1d6a-4c93-afbe-7f02f4d52aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf0ebadb-5a2b-45b1-8d1c-fcf82ffba920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我要去上学=>i have to go to school .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我要去上学\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5cda0329-3e2c-4a1a-9b44-ce61d99ebff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名程序员=>i'm a bit young .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名程序员\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f44e4ffb-0ae1-4a9a-808a-97b0aa3590f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一名飞行员=>i'm a nurse .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我是一名飞行员\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb1aa00c-ade6-477a-b689-ec210c0ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我在飞=>i'm wounded .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"我在飞\"\n",
    "translation, dec_attention_weight_seq = predict_seq2seq(net, sentence, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "print(f'{sentence}=>{translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eaf9f6-8f45-49fb-b28b-eac2f35b2f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf9b4f-261f-4349-ba68-61470cc5771f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923167a-73c9-4568-a860-56bc3bff5747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f617e-f853-4e98-9ca3-f09ad8f09a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5c98e-18c5-4842-a115-3a1244b8dc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b465cc7-9e93-49dc-aba7-545a35afd936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596655d2-4c32-4602-b90b-b6bc8af75fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18d958-6a13-48e2-a0d3-84b44fb1809c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d66a3a-35f2-4e68-a48e-3376c3462f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620b6e5-e18b-4c82-9d87-cb435d423fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64801c-bc89-44b4-ae34-0aa7e1951bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff23092-9bc6-448b-9174-554149a30b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82627b04-cf13-40ab-8351-b1676a189627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e73c28-d2d4-4da0-8204-a024f90c86bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
